{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyisc;\n",
    "import numpy as np\n",
    "from scipy.stats import poisson, norm, multivariate_normal\n",
    "%matplotlib inline\n",
    "from pylab import plot, figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 3\n",
    "data_len = 10000\n",
    "anomaly_len = 15\n",
    "data = None\n",
    "\n",
    "#Create the normal data \n",
    "for i in range(class_num):\n",
    "    \n",
    "    po_normal = poisson(10+i)\n",
    "    po_normal2 = poisson(2+i)\n",
    "    gs_normal = norm(1+i, 12)\n",
    "    \n",
    "    tmp = np.column_stack(\n",
    "        [\n",
    "            [1] * (data_len),\n",
    "            list(po_normal.rvs(data_len)),\n",
    "            list(po_normal2.rvs(data_len)),\n",
    "            list(gs_normal.rvs(data_len)),\n",
    "            [i] * (data_len),\n",
    "        ]\n",
    "    )\n",
    "    if data is None:\n",
    "        data = tmp\n",
    "    else:\n",
    "        data = np.r_[data,tmp]\n",
    "        \n",
    "# Create Anomaly Data\n",
    "for i in range(class_num):\n",
    "    \n",
    "    po_anomaly = poisson(25+i)\n",
    "    po_anomaly2 = poisson(3+i)\n",
    "    gs_anomaly = norm(2+i,30)\n",
    "\n",
    "    tmp = np.column_stack(\n",
    "        [\n",
    "            [1] * (anomaly_len),\n",
    "            list(po_anomaly.rvs(anomaly_len)),\n",
    "            list(po_anomaly2.rvs(anomaly_len)),\n",
    "            list(gs_anomaly.rvs(anomaly_len)),\n",
    "            [i] * (anomaly_len),\n",
    "        ]\n",
    "    )\n",
    "    if data is None:\n",
    "        data = tmp\n",
    "    else:\n",
    "        data = np.r_[data,tmp]\n",
    "        \n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector = pyisc.AnomalyDetector(\n",
    "    component_models=[\n",
    "        pyisc.P_PoissonOnesided(1,0), # One sided for frequency 1\n",
    "        pyisc.P_Poisson(2,0), # Two Sided for frequency 2\n",
    "        pyisc.P_Gaussian(3) # Gaussian for Class\n",
    "    ],\n",
    "    output_combination_rule=pyisc.cr_max #Maximum of the anomaly scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector.fit(data, y=4) #Fit the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = anomaly_detector.anomaly_score(data, y=4) #Get the anomaly scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataframe with the overall anomaly scores\n",
    "from pandas import DataFrame\n",
    "df= DataFrame(data[:15], columns=['Class','#Days', 'Freq1','Freq2','Class'])\n",
    "#df= DataFrame(data, columns=['Class','#Days', 'Freq1','Freq2','Measure'])\n",
    "#print df\n",
    "df['Anomaly Score'] = scores[:15]\n",
    "print df.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the anomaly scores for the 45 datapoints with the class and measure together\n",
    "df= DataFrame(data[-45:], columns=['#Days', 'Freq1','Freq2','Measure','Class'])\n",
    "#Parse their anomaly scores as well\n",
    "df['Anomaly Score'] = scores[-45:]\n",
    "print df.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the anomaly scores against the data points\n",
    "plot(scores, '.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the anomaly scores of each columns and the final anomaly score which is max of those columns\n",
    "score_details = anomaly_detector.anomaly_score_details(data,y=4)\n",
    "df= DataFrame(data[-45:], columns=['#Days', 'Freq1','Freq2','Measure','Class'])\n",
    "df['Anomaly:Freq1'] = [detail[2][0] for detail in score_details[-45:]]   # Anomaly Score of Freq1\n",
    "df['Anomaly:Freq2'] = [detail[2][1] for detail in score_details[-45:]]   # Anomaly Score of Freq2\n",
    "df['Anomaly:Measure'] = [detail[2][2] for detail in score_details[-45:]] # Anomaly Score of Measure\n",
    "df['Anomaly Score'] = [detail[0] for detail in score_details[-45:]]      # Combined Anomaly Score\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the data for classification using the same logic as above and pass this data to the anomaly model already created\n",
    "data2 = None\n",
    "true_classes = []\n",
    "length = 1000\n",
    "for i in range(n_classes):\n",
    "    po_normal = poisson(10+i)\n",
    "    po_normal2 = poisson(2+i)\n",
    "    gs_normal = norm(1+i, 12)\n",
    "    tmp = np.column_stack(\n",
    "        [\n",
    "            [1] * (length),\n",
    "            list(po_normal.rvs(length)),\n",
    "            list(po_normal2.rvs(length)),\n",
    "            list(gs_normal.rvs(length)),\n",
    "            [None] * (length),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    true_classes += [i] * length\n",
    "    \n",
    "    if data2 is None:\n",
    "        data2 = tmp\n",
    "    else:\n",
    "        data2 = np.r_[data2,tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the classifier for the pyISC framework using the anomaly detection model already created above\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "result = DataFrame(columns=['Algorithm','Accuracy'])\n",
    "clf = pyisc.SklearnClassifier.clf(anomaly_detector)\n",
    "predicted_classes = clf.predict(data2)\n",
    "acc = accuracy_score(true_classes, predicted_classes)\n",
    "result.loc[0] = ['pyISC classifier', acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the Scikit-Learn library import the classification algorithms\n",
    "#We use gaussian, KNN, Random Forest\n",
    "#Set the parameters to the initial values as mentioned in the paper\n",
    "#Get the prediction and comparison with the pyISC classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = data.T[:-1].T\n",
    "y = data.T[-1]\n",
    "count = 1\n",
    "for name, clf in zip(['GaussianNB',\n",
    "                      'KNeighborsClassifier', \n",
    "                      'RandomForestClassifier'],\n",
    "                     [GaussianNB(), \n",
    "                      KNeighborsClassifier(n_neighbors=1000,weights='distance'), \n",
    "                      RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]):\n",
    "    clf.fit(X,y);\n",
    "\n",
    "    predicted_classes_SK= clf.predict(data2.T[:-1].T)\n",
    "    acc = accuracy_score(true_classes,predicted_classes_SK)\n",
    "    result.loc[count] = [name, acc]\n",
    "    count += 1\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
